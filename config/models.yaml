local_models:
  tinyllama:
    model_id: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0
    max_tokens: 2048
    quantization: "4bit"
    suitable_for: ["simple"]
    
  qwen_1_5b:
    model_id: "Qwen/Qwen2.5-1.5B-Instruct"
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0
    max_tokens: 4096
    quantization: "4bit"
    suitable_for: ["simple", "medium"]

# Groq models - FREE and ultra-fast! Get API key at: https://console.groq.com/keys
# Tiered for cost optimization: simple→fast small model, complex→powerful large model
groq_models:
  # Tier 1: Fast & Light (for SIMPLE queries) - 560 tokens/sec
  llama_3_1_8b:
    model_id: "llama-3.1-8b-instant"
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0
    max_tokens: 8192
    tier: "simple"
    speed: "560 tokens/sec"
    suitable_for: ["simple"]
    
  # Tier 2: Balanced (for MEDIUM queries) - 400 tokens/sec
  qwen_32b:
    model_id: "qwen-qwq-32b"
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0
    max_tokens: 32768
    tier: "medium"
    speed: "400 tokens/sec"
    suitable_for: ["medium"]
    
  # Tier 3: Powerful (for COMPLEX queries) - 280 tokens/sec
  llama_3_3_70b:
    model_id: "llama-3.3-70b-versatile"
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0
    max_tokens: 32768
    tier: "complex"
    speed: "280 tokens/sec"
    suitable_for: ["complex"]

api_models:
  gpt_4o_mini:
    model_id: "gpt-4o-mini"
    provider: "openai"
    cost_per_1k_input: 0.150
    cost_per_1k_output: 0.600
    max_tokens: 16384
    suitable_for: ["medium", "complex"]
    
  gpt_4o:
    model_id: "gpt-4o"
    provider: "openai"
    cost_per_1k_input: 2.50
    cost_per_1k_output: 10.00
    max_tokens: 16384
    suitable_for: ["complex"]
    
  claude_3_haiku:
    model_id: "claude-3-haiku-20240307"
    provider: "anthropic"
    cost_per_1k_input: 0.25
    cost_per_1k_output: 1.25
    max_tokens: 4096
    suitable_for: ["medium", "complex"]
